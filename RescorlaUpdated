% Computational Modeling of Behaviour, Spring 2022
% function [a, r] = Model3(Trial, rProbs, learnRate, beta) 

% number of trials, 
nTrial = 160;
Options = 2; % There are only two possible options

% Reward probabilities of the two options
rProbs = [0.8 0.2];
randomProb = randi([0.8, 0.2], 1); %Chooses one number between 0.2 and 0.8 randomly.
randomn = rand(15,60);
learnRate = 0.02; % ADD STEP ITERATION FOR THIS
choicePolicy = 'softmax';
    
choiceProb = zeros(nTrial, Options);
a = zeros(nTrial,1); %using alpha for betting/not betting
r = NaN(nTrial,1); %using this for winning or losing
    
Q = [0.5 0.5];

for i = 0:randomn:160
    %randomn = rand(15,60);    
    for t = i:(i+randomn)
        
        beta = 5; %create array with {1,5,10,20,100} and choose randomly. Using beta to mimic stakes.
        % compute choice probabilities
        choiceProb(t,:) = exp(beta*Q) / sum(exp(beta*Q));
        
        % deciding option
        a(t) = modelHPChoose(choiceProb(t,:),2);
        
        % generate reward based on choice
        r(t) = rand < rProbs(a(t));
        
        % update values
        delta = r(t) - Q(a(t));
        Q(a(t)) = Q(a(t)) + alpha * delta;

        %Changing reward prob randomly
        if randomProb == 0.2
            randomProb = 0.8;
        else
            randomProb = 0.2;
        end
    end
end
